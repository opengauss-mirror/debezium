# name: source端连接器名称
name=connect-postgres-source
# connector.class: 连接器的启动类
connector.class=io.debezium.connector.postgresql.PostgresConnector
# database.hostname: postgres数据库主机ip
database.hostname=127.0.0.1
# database.port: postgres数据库端口
database.port=5432
# database.user: postgres数据库用户
 database.user=postgres
# database.password: postgres数据库用户密码
database.password=********
# database.server.name: postgres数据库实例名称
database.server.name=postgres
# tasks.max: 连接器创建的最大任务数，固定为1
tasks.max=1
# database.dbname: postgres数据库名称
database.dbname=public
# slot.name: postgres逻辑复制槽名称
slot.name=test_slot
# 创建逻辑复制槽插件名称
plugin.name=wal2json
# xlog.location：增量迁移参数。自定义xlog位置，建立逻辑复制槽和发布之后，可通过此参数指定从哪个位置开始迁移，无默认值，有此需求的场景可配。
# xlog.location=94/578140B0
# transforms: kafka topic路由转发名称
transforms=route
# kafka topic路由转发类型
transforms.route.type=org.apache.kafka.connect.transforms.RegexRouter
# transforms.route.regex: kafka topic路由转发正则匹配表达式，正则匹配按照前缀匹配
# 将dml topic路由转发至同一topic，其中正则表达式中的opengauss与database.server.name对应
transforms.route.regex=^postgres(.*)
# transforms.route.replacement: kafka topic路由转发后的topic名称，该参数与opengauss-sink.properties的配置项topics相对应
transforms.route.replacement=postgres_server_topic
# 配置debezium对小数类型的处理模式, 用于增量迁移。precise(默认):使用Bigdecimal处理，string:使用string处理，double:使用double表示。
decimal.handling.mode=string
# include.unknown.datatypes: 兼容更多数据类型，默认为true
include.unknown.datatypes=true
# slot.drop.on.stop：停止时是否删除逻辑复制槽与发布订阅，默认为false
slot.drop.on.stop=false
# snapshot.mode=always，debezium原生参数，pg迁移中固定为alway。
snapshot.mode=always
# xlog.location：自定义xlog位置，建立逻辑复制槽和发布之后，可通过此参数指定从哪个位置开始迁移，无默认值，有此需求的场景可配
#xlog.location=94/578140B0
# commit.process.while.running：布尔值，默认为false，通过该配置项选择是否上报迁移进度
commit.process.while.running=false
# source.process.file.path：迁移进度文件的输出路径，只有commit.process.while.running=true时才起作用，默认在迁移插件同一目录下
source.process.file.path=/***/***/***/
# commit.time.interval：迁移进度上报的时间间隔，取int型整数，默认为1，单位：s
commit.time.interval=1
# create.count.info.path：记录源端有效日志生产总数的文件输出路径，需与sink端的此配置项相同，默认与迁移插件在同一目录下
create.count.info.path=/***/***/***/
# process.file.count.limit：进度目录下文件数目限制值，如果进度目录下的文件数目超过该值，工具启动时会按时间从早到晚删除多余的文件，默认值为10
process.file.count.limit=10
# process.file.time.limit：进度文件保存时长，超过该时长的文件会在工具下次启动时删除，默认值为168，单位：小时
process.file.time.limit=168
# append.write：进度文件写入方式，true表示追加写入，false表示覆盖写入，默认值为false
append.write=false
# file.size.limit：文件大小限制，超过该限制值工具会另启新文件写入，默认为10，单位：兆
file.size.limit=10
# 全量数据采集后写入文件的位置
export.csv.path=/***/***/***/
# 全量数据文件大小划分配置，支持K、M、G大小配置，没有单位默认按照M单位处理，默认值为 2M
export.file.size=2M
# 文件夹大小控制 支持K、M、G大小配置，没有单位时默认按照G单位处理，默认值为null
export.csv.path.size=2G
# min.start.memory: 自定义debezium最小启动内存
min.start.memory=256M
# max.start.memory: 自定义debezium最大启动内存
max.start.memory=2G
# reconnection.number: 迁移过程中数据库异常时，尝试重连的次数，默认值12，需要与reconnection.time.interval配合使用
reconnection.number=12
# reconnection.time.interval: 迁移过程中数据库异常时，每次尝试重连的时间间隔，单位毫秒（ms），默认值5000，需要与reconnection.number配合使用
reconnection.time.interval=5000
# wal.sender.timeout:用于反向迁移建立openGauss会话时，设置guc参数wal_sender_timeout的值，单位毫秒（ms），默认值6000。反向迁移停止时，会将此guc参数值恢复到反向迁移启动前的值。
# wal_sender_timeout参数说明：设置发送端等待事务日志接收端接收日志的最大等待时间。当openGauss短时间内新增数据量较大时，会出现反向迁移工具在此guc参数默认值6s内来不及接收事务日志而报错的情况，需要将此guc参数值调大解决。
# 由于wal_sender_timeout参数受wal_receiver_timeout参数的限制，要求前者不能大于后者。因此反向迁移启动时，如果配置wal_sender_timeout参数为更大值时，则会同步增大wal_receiver_timeout参数的值，反向迁移停止时，同步恢复两者的值。
# wal_receiver_timeout参数说明：设置备机从主机接收数据的最大等待时间。
wal.sender.timeout=6000
# 迁移类型，无默认值。full:全量迁移,incremental:增量，object:对象
migration.type=full
# 对象迁移时生效，是否迁移视图
migration.view=true
# 对象迁移时生效，是否迁移函数和存储过程
migration.func=true
# 对象迁移时生效，是否迁移触发器
migration.trigger=true
# schema白名单
schema.include.list=public
# 表白名单
table.include.list=public.t1
# schema黑名单
schema.exclude.list=schema1
# 表黑名单
table.exclude.list=schema1.t1
# 数据导出并发度
migration.workers=5
# 分页抽取一次抽取的分片数量。取值范围为(0, 100000]，默认值50。需根据实际jvm内存进行配置。
export.page.number=50
# 指定如何处理更改事件的 TRUNCATE操作（仅在 pg11+ pgoutput 插件上受支持），包括skip和include。默认值为skip。
truncate.handling.mode=skip
