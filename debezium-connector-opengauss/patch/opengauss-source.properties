# name: source端连接器名称
name=connect-opengauss-source
# connector.class: 连接器的启动类
connector.class=io.debezium.connector.opengauss.OpengaussConnector
# database.hostname: opengauss数据库主机ip
database.hostname=127.0.0.1
# database.port: opengauss数据库端口
database.port=5432
# database.iscluster: opengauss数据库是否为集群，可选择true/false，选择true时，需配置database.standby.hostnames和database.standby.ports
database.iscluster=false
# database.standby.hostnames: opengauss数据库备机ip1,ip2,...，多个备机ip间用英文逗号隔开
database.standby.hostnames=127.0.0.2,127.0.0.3
# database.standby.ports: opengauss数据库备机端口port1,port2,...，多个备机port间用英文逗号隔开，注意需要与备机ip1,ip2,...保持对应
database.standby.ports=5432,5432
# database.user: opengauss数据库用户
database.user=db_user
# database.password: opengauss数据库用户密码
database.password=*****
# database.server.name: opengauss数据库实例名称
database.server.name=opengauss
# tasks.max: 连接器创建的最大任务数
tasks.max=1
# database.dbname: opengauss数据库名称
database.dbname=db_name
# slot.name: opengauss逻辑复制槽名称
slot.name=slot_name
# 创建逻辑复制槽的插件名称，默认为pgoutput，可设置为mppdb_decoding实现并行解码。
# 逻辑复制槽为mppdb_decoding时，设置解码线程并行度：parallel.decode.num=1~20（默认值：15）。
plugin.name=pgoutput
# transforms: kafka topic路由转发名称
transforms=route
# kafka topic路由转发类型
transforms.route.type=org.apache.kafka.connect.transforms.RegexRouter
# transforms.route.regex: kafka topic路由转发正则匹配表达式，正则匹配按照前缀匹配
# 将dml topic路由转发至同一topic，其中正则表达式中的opengauss与database.server.name对应
transforms.route.regex=^opengauss(.*)
# transforms.route.replacement: kafka topic路由转发后的topic名称，该参数与opengauss-sink.properties的配置项topics相对应
transforms.route.replacement=dml_topic
# 配置debezium对小数类型的处理模式
decimal.handling.mode=string
# include.unknown.datatypes: 兼容更多数据类型，默认为true
include.unknown.datatypes=true
# slot.drop.on.stop=true：停止时删除逻辑复制槽与发布订阅，默认为true
slot.drop.on.stop=true
# snapshot.mode=never：快照模式，默认为never
snapshot.mode=never
# xlog.location：自定义xlog位置，建立逻辑复制槽和发布之后，可通过此参数指定从哪个位置开始迁移，无默认值，有此需求的场景可配
#xlog.location=94/578140B0
# commit.process.while.running：布尔值，默认为false，通过该配置项选择是否上报迁移进度
commit.process.while.running=true
# source.process.file.path：迁移进度文件的输出路径，只有commit.process.while.running=true时才起作用，默认在迁移插件同一目录下
source.process.file.path=/***/***/***/
# commit.time.interval：迁移进度上报的时间间隔，取int型整数，默认为1，单位：s
commit.time.interval=1
# create.count.info.path：记录源端有效日志生产总数的文件输出路径，需与sink端的此配置项相同，默认与迁移插件在同一目录下
create.count.info.path=/***/***/***/
# process.file.count.limit：进度目录下文件数目限制值，如果进度目录下的文件数目超过该值，工具启动时会按时间从早到晚删除多余的文件，默认值为10
process.file.count.limit=10
# process.file.time.limit：进度文件保存时长，超过该时长的文件会在工具下次启动时删除，默认值为168，单位：小时
process.file.time.limit=168
# append.write：进度文件写入方式，true表示追加写入，false表示覆盖写入，默认值为false
append.write=false
# file.size.limit：文件大小限制，超过该限制值工具会另启新文件写入，默认为10，单位：兆
file.size.limit=10
# 全量数据采集后写入文件的位置
export.csv.path=/***/***/***/
# 全量数据文件大小划分配置，支持K、M、G大小配置，没有单位默认按照M单位处理，默认值为 2M
export.file.size=2M
# 文件夹大小控制 支持K、M、G大小配置，没有单位时默认按照G单位处理，默认值为null
export.csv.path.size=2G
# min.start.memory: 自定义debezium最小启动内存
min.start.memory=256M
# max.start.memory: 自定义debezium最大启动内存
max.start.memory=2G
# reconnection.number: 迁移过程中数据库异常时，尝试重连的次数，默认值12，需要与reconnection.time.interval配合使用
reconnection.number=12
# reconnection.time.interval: 迁移过程中数据库异常时，每次尝试重连的时间间隔，单位毫秒（ms），默认值5000，需要与reconnection.number配合使用
reconnection.time.interval=5000
# wal.sender.timeout:用于反向迁移建立openGauss会话时，设置guc参数wal_sender_timeout的值，单位毫秒（ms），默认值6000。反向迁移停止时，会将此guc参数值恢复到反向迁移启动前的值。
# wal_sender_timeout参数说明：设置发送端等待事务日志接收端接收日志的最大等待时间。当openGauss短时间内新增数据量较大时，会出现反向迁移工具在此guc参数默认值6s内来不及接收事务日志而报错的情况，需要将此guc参数值调大解决。
# 由于wal_sender_timeout参数受wal_receiver_timeout参数的限制，要求前者不能大于后者。因此反向迁移启动时，如果配置wal_sender_timeout参数为更大值时，则会同步增大wal_receiver_timeout参数的值，反向迁移停止时，同步恢复两者的值。
# wal_receiver_timeout参数说明：设置备机从主机接收数据的最大等待时间。
wal.sender.timeout=6000
